{
    "version": "https://jsonfeed.org/version/1",
    "title": "minz的筆記本 • All posts by \"ai\" category",
    "description": "",
    "home_page_url": "https://blog.minz.li",
    "items": [
        {
            "id": "https://blog.minz.li/AI/OpenWebui_direct/",
            "url": "https://blog.minz.li/AI/OpenWebui_direct/",
            "title": "新版本的 Open-webui  使用者可以使用自己的 API key",
            "date_published": "2025-02-26T16:00:00.000Z",
            "content_html": "<p>Open-webui 在 <a href=\"https://github.com/open-webui/open-webui/releases/tag/v0.5.11\">0.5.11 版本</a>後，使用者可以使用自己的 API key。</p>\n<ol>\n<li>註冊一個帳號</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_1.webp\" alt=\"\" width=\"80%\" /></p>\n<details class=\"info\"><summary>如果出現帳號待啟用，需要通知管理員開啟權限</summary><div>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_2.webp\" alt=\"\" width=\"80%\" /></p>\n</div></details>\n<ol start=\"2\">\n<li>點選右上角的使用者的圖像，選擇設定</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_3.webp\" alt=\"\" width=\"80%\" /></p>\n<ol start=\"3\">\n<li>輸入  <code>API URL</code>  跟  <code>key</code></li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_4.webp\" alt=\"\" width=\"80%\" /></p>\n<ol start=\"4\">\n<li>回到首頁按下 F5 重新整理後刷新則會自動取得模型</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_5.webp\" alt=\"\" width=\"80%\" /></p>\n",
            "tags": [
                "Open-webui",
                "Custom",
                "API"
            ]
        },
        {
            "id": "https://blog.minz.li/AI/AI-Accelerators/",
            "url": "https://blog.minz.li/AI/AI-Accelerators/",
            "title": "超越 GPU 在 Groq/Cerebras/SambaNova 使用高速輸出的 Deepseek",
            "date_published": "2025-02-19T16:00:00.000Z",
            "content_html": "<h1 id=\"groq-介紹\"><a class=\"anchor\" href=\"#groq-介紹\">#</a> Groq 介紹</h1>\n<p>Groq 的主要產品是 LPU (Language Processing Units)，能夠大幅提升模型的推論速度，這表示模型回答的速度加快，比 GPT-4o 快了數倍。<br />\nGroq 的 實驗性模型  <code>llama-3.3-70b-specdec</code>  在 GroqCloud 上的推論速度最快可以達到 <a href=\"https://groq.com/groq-first-generation-14nm-chip-just-got-a-6x-speed-boost-introducing-llama-3-1-70b-speculative-decoding-on-groqcloud/\">1,660 tokens/s</a> 。</p>\n<ul>\n<li>低延遲 (Seconds to First Token Received)</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://groq.com/wp-content/uploads/2024/11/latency-1536x762.jpg.webp\" alt=\"\" /></p>\n<ul>\n<li>高性能 (High Output Tokens per Second)</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://groq.com/wp-content/uploads/2024/11/output-speed2-1536x762.jpg.webp\" alt=\"\" /></p>\n<h2 id=\"可以使用的-models\"><a class=\"anchor\" href=\"#可以使用的-models\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://console.groq.com/docs/models\">https://console.groq.com/docs/models</a> 查看可以使用的模型</li>\n<li>目前多為 llama、gemma、whisper 系列</li>\n</ul>\n<h2 id=\"使用\"><a class=\"anchor\" href=\"#使用\">#</a> 使用</h2>\n<p>可以在官方網站 <a href=\"https://groq.com/\">https://groq.com/</a> 或是<a href=\"https://console.groq.com/playground\"> playground</a> 直接使用</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/groq_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api\"><a class=\"anchor\" href=\"#api\">#</a> API</h2>\n<p><a href=\"https://console.groq.com/keys\">https://console.groq.com/keys</a><br />\n 在左邊 API Keys 的選單中點擊 Create API Key，目前免費層級有提供一定的額度使用，API 兼容 openai 格式，修改 base_url 和 model 後可以直接使用。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> openai</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>client <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>OpenAI<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    base_url<span class=\"token operator\">=</span><span class=\"token string\">\"https://api.groq.com/openai/v1\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    api_key<span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"GROQ_API_KEY\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"cerebras-介紹\"><a class=\"anchor\" href=\"#cerebras-介紹\">#</a> Cerebras 介紹</h1>\n<p>Cerebras 研發的產品是 Wafer Scale Engine（WSE，晶圓級引擎），是一款 超大型 AI 加速晶片。</p>\n<ul>\n<li><a href=\"https://cerebras.ai/blog/cerebras-launches-worlds-fastest-deepseek-r1-llama-70b-inference\">推理速度</a></li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://cerebras.ai/wp-content/uploads/2025/01/deepseek-chart.png\" alt=\"\" /></p>\n<h2 id=\"可以使用的-models-2\"><a class=\"anchor\" href=\"#可以使用的-models-2\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://inference-docs.cerebras.ai/introduction\">https://inference-docs.cerebras.ai/introduction</a> 查看可以使用的模型</li>\n<li>目前只有 llama 系列</li>\n</ul>\n<h2 id=\"使用-2\"><a class=\"anchor\" href=\"#使用-2\">#</a> 使用</h2>\n<p>可以在首頁<a href=\"https://inference.cerebras.ai/\"> https://inference.cerebras.ai/</a> 直接使用</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/cerebras_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api-2\"><a class=\"anchor\" href=\"#api-2\">#</a> API</h2>\n<p><a href=\"https://cloud.cerebras.ai/platform/\">https://cloud.cerebras.ai/platform/</a><br />\n 首頁右上方點擊 Get API Key，<strong>需要填寫 Google 表單申請</strong>，目前免費層級有提供一定的額度使用，<br />\nAPI 兼容 openai 格式，修改 base_url 為  <code>https://api.cerebras.ai/v1</code>  和  <code>model</code>  後可以直接使用。</p>\n<h1 id=\"sambanova-介紹\"><a class=\"anchor\" href=\"#sambanova-介紹\">#</a> Sambanova 介紹</h1>\n<p>SambaNova 開發的產品是 SN40L ，Reconfigurable Dataflow Unit (RDU)，專為 AI 推理與訓練設計的整合式加速晶片。</p>\n<ul>\n<li>SambaNova 與其他競品的比較</li>\n<li><a href=\"https://sambanova.ai/blog/sn40l-chip-best-inference-solution\">來源</a></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">指標</th>\n<th style=\"text-align:center\">SambaNova SN40L</th>\n<th style=\"text-align:center\">Cerebras WSE-3</th>\n<th style=\"text-align:center\">Groq LPU</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">晶片數（70B 模型）</td>\n<td style=\"text-align:center\">16 晶片</td>\n<td style=\"text-align:center\">336 晶片（4 晶圓）</td>\n<td style=\"text-align:center\">576 晶片</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">算力密度</td>\n<td style=\"text-align:center\">優於 Groq 40 倍 / Cerebras 10 倍</td>\n<td style=\"text-align:center\">高算力但受限於 SRAM 與多晶圓管線並行成本</td>\n<td style=\"text-align:center\">需大量晶片互連以補足 SRAM 容量限制</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">記憶體架構</td>\n<td style=\"text-align:center\">SRAM + HBM + DDR</td>\n<td style=\"text-align:center\">全 SRAM</td>\n<td style=\"text-align:center\">全 SRAM</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">量化需求</td>\n<td style=\"text-align:center\">無（16-bit 原生）</td>\n<td style=\"text-align:center\">無（官方宣稱使用 16-bit）</td>\n<td style=\"text-align:center\"><strong>推測</strong>需 int8 量化</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"可以使用的-models-3\"><a class=\"anchor\" href=\"#可以使用的-models-3\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://docs.sambanova.ai/cloud/docs/get-started/supported-models\">https://docs.sambanova.ai/cloud/docs/get-started/supported-models</a> 查看可以使用的模型</li>\n<li>目前只有 DeepSeek、llama、Qwen 系列</li>\n<li>DeepSeek R1 671B 需要填表申請</li>\n</ul>\n<h2 id=\"使用-3\"><a class=\"anchor\" href=\"#使用-3\">#</a> 使用</h2>\n<p>可以在官方網站 <a href=\"https://cloud.sambanova.ai/\">playground</a> 直接使用<br />\n<img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/sambanova_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api-3\"><a class=\"anchor\" href=\"#api-3\">#</a> API</h2>\n<p><a href=\"https://cloud.sambanova.ai/apis\">https://cloud.sambanova.ai/apis</a><br />\n 在左邊 API Keys 的選單中點擊 Create API Key，目前提供新用戶 5 美元 (3 個月到期)，<br />\nAPI 兼容 openai 格式，修改 base_url 為  <code>https://api.sambanova.ai</code>  和 model 後可以直接使用。</p>\n",
            "tags": [
                "Groq",
                "Cerebras",
                "SambaNova",
                "Deepseek",
                "llama"
            ]
        }
    ]
}