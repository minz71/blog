{
    "version": "https://jsonfeed.org/version/1",
    "title": "minz的筆記本 • All posts by \"ai\" category",
    "description": "",
    "home_page_url": "https://blog.minz.li",
    "items": [
        {
            "id": "https://blog.minz.li/AI/OpenWebui_direct/",
            "url": "https://blog.minz.li/AI/OpenWebui_direct/",
            "title": "新版本的 Open-webui  使用者可以使用自己的 API key",
            "date_published": "2025-02-26T16:00:00.000Z",
            "content_html": "<p>Open-webui 在 <a href=\"https://github.com/open-webui/open-webui/releases/tag/v0.5.11\">0.5.11 版本</a>後，使用者可以使用自己的 API key。</p>\n<ol>\n<li>註冊一個帳號</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_1.webp\" alt=\"\" width=\"80%\" /></p>\n<details class=\"info\"><summary>如果出現帳號待啟用，需要通知管理員開啟權限</summary><div>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_2.webp\" alt=\"\" width=\"80%\" /></p>\n</div></details>\n<ol start=\"2\">\n<li>點選右上角的使用者的圖像，選擇設定</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_3.webp\" alt=\"\" width=\"80%\" /></p>\n<ol start=\"3\">\n<li>輸入  <code>API URL</code>  跟  <code>key</code></li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_4.webp\" alt=\"\" width=\"80%\" /></p>\n<ol start=\"4\">\n<li>回到首頁按下 F5 重新整理後刷新則會自動取得模型</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/OpenWebui/OpenWebui_5.webp\" alt=\"\" width=\"80%\" /></p>\n",
            "tags": [
                "Open-webui",
                "Custom",
                "API"
            ]
        },
        {
            "id": "https://blog.minz.li/AI/AI_BenchMark/",
            "url": "https://blog.minz.li/AI/AI_BenchMark/",
            "title": "AI 大語言模型評測網站",
            "date_published": "2025-02-23T16:00:00.000Z",
            "content_html": "<h1 id=\"介紹\"><a class=\"anchor\" href=\"#介紹\">#</a> 介紹</h1>\n<p>隨著 AI 大語言模型的快速迭代，能力也增強了許多，可以在以下的網站查看目前模型的排名。</p>\n<h1 id=\"lmsysorg\"><a class=\"anchor\" href=\"#lmsysorg\">#</a> <a href=\"http://LMSYS.Org\">LMSYS.Org</a></h1>\n<p>LMSYS Org (Large Model Systems Organization) 是一個開放的研究組織，由 UC Berkeley 的學生和教師與 UCSD 和 CMU 合作創立。<br />\n旨在通過共同開發開放模型、數據集、系統和評估工具，使大型模型對所有人都能夠接觸和使用。<br />\n希望建立一個開放和透明的平臺，提供語言模型基準數據和評估工具，幫助研究人員和開發者更好地理解和提升他們的模型性能。</p>\n<div class=\"note info\">\n<p>本文主要介紹 Chatbot Arena，LMSYS Org 有其他的 projects。<br />\n詳情可參考: <a href=\"https://lmsys.org/projects/\">https://lmsys.org/projects/</a></p>\n</div>\n<h2 id=\"chatbot-arena\"><a class=\"anchor\" href=\"#chatbot-arena\">#</a> Chatbot Arena</h2>\n<div class=\"links\"><div class=\"item\" title=\"LMSYS\" style=\"--block-color:#e9546b;\"><a href=\"https://lmarena.ai/\" class=\"image\" data-background-image=\"https://lmarena.ai/favicon.jpeg\"></a>\n        <div class=\"info\">\n        <a href=\"https://lmarena.ai/\" class=\"title\">LMSYS</a>\n        <p class=\"desc\">arena.lmsys.org</p>\n        </div></div></div>\n<ol>\n<li>⚔️ Arena (battle)<br />\n 使用者可以輸入問題，會隨機提供不同的模型回答，使用者可以對回答較佳的模型投票，投票後會顯示剛剛回答的模型。</li>\n<li>⚔️ Arena (side-by-side)<br />\n 可以讓使用者選擇 2 個<strong>指定</strong>的模型，使用者可以對回答較佳的模型投票。</li>\n<li>💬 Direct Chat<br />\n 使用者可以直接和模型對話，可以選擇指定的模型。</li>\n</ol>\n<ul>\n<li>向模型提問的範例：</li>\n</ul>\n<figure class=\"highlight plain\"><figcaption data-lang=\"plain\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>今天有 3 個蘋果，我昨天吃了 1 個，請問還剩下幾個?</pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/lmsysArena1.webp\" alt=\"\" title=\"詢問模型\" width=\"80%\" /></p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/lmsysArena2.webp\" alt=\"\" title=\"投票後\" width=\"80%\" /></p>\n<h2 id=\"llm-排行榜\"><a class=\"anchor\" href=\"#llm-排行榜\">#</a> LLM 排行榜</h2>\n<p><a href=\"http://lmsys.org\">lmsys.org</a> 每隔一段時間都會發布排行榜，可以做為模型能力的參考，可以選擇不同的分類，查看該分類的排行榜。</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/lmsysLeaderBoard.webp\" alt=\"\" title=\"LLM 排行榜\" width=\"80%\" /></p>\n<h2 id=\"贊助商\"><a class=\"anchor\" href=\"#贊助商\">#</a> 贊助商</h2>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/lmsysDonations.webp\" alt=\"\" title=\"LMSYS Donation\" width=\"60%\" /><br />\n可以看到有許多大公司都贊助了 LMSYS，<br />\n在新模型發布時，都會在第一時間提供給最新的語言模型，<br />\n例如當時流傳的 m-also-a-good-gpt2-chatbot，也就是現在的 GPT-4o。</p>\n<h2 id=\"用戶能判斷模型的能力嗎\"><a class=\"anchor\" href=\"#用戶能判斷模型的能力嗎\">#</a> 用戶能判斷模型的能力嗎？</h2>\n<p>在 GPT-4o-mini 勝出其他大模型後，許多人對這個榜單提出質疑，因此提供用戶的<a href=\"https://huggingface.co/spaces/lmsys/gpt-4o-mini_battles\">對話與投票紀錄</a>，<br />\n<a href=\"https://lmsys.org/blog/2024-08-28-style-control/\">之後也提出  <code>style control</code>  功能</a>，在模型 A 在內容上更優秀，而模型 B 在風格 (排版) 上更優秀，<br />\n目標是要有辦法區分模型分數是來自 <code>內容</code> 或是 <code>風格</code> 。</p>\n<h1 id=\"aider-leaderboards\"><a class=\"anchor\" href=\"#aider-leaderboards\">#</a> Aider Leaderboards</h1>\n<div class=\"links\"><div class=\"item\" title=\"Aider Leaderboards\" style=\"--block-color:#e9546b;\"><a href=\"https://aider.chat/docs/leaderboards/\" class=\"image\" data-background-image=\"https://aider.chat/assets/icons/favicon-32x32.png\"></a>\n        <div class=\"info\">\n        <a href=\"https://aider.chat/docs/leaderboards/\" class=\"title\">Aider Leaderboards</a>\n        <p class=\"desc\">https://aider.chat/docs/leaderboards/</p>\n        </div></div></div>\n<ul>\n<li>Aider 是一個開源的 AI 程式碼撰寫工具。</li>\n</ul>\n<p>Aider LLM Leaderboards 是由 Aider 開發的一組基準測試，用於評估大型語言模型（LLM）編輯程式碼的能力。<br />\n這些基準測試專注於模型編輯<strong>現有程式碼</strong>的能力，確保模型能夠一致地遵循系統提示詞（Prompt）完成編輯任務，適合評估在程式碼編輯的表現。</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/aider_leaderboards.webp\" alt=\"\" title=\"Aider Leaderboards\" width=\"80%\" /></p>\n<h2 id=\"如何進行基準測試\"><a class=\"anchor\" href=\"#如何進行基準測試\">#</a> 如何進行基準測試？</h2>\n<p>基準測試是 <a href=\"https://aider.chat/2024/12/21/polyglot.html#the-polyglot-benchmark\">Aider’s polyglot benchmark</a>，選取 Exercism 的 225 個困難的程式練習，測量模型<strong>完成任務</strong>的百分比以及使用<strong>正確編輯格式</strong>的百分比。</p>\n<ul>\n<li>diff 輸出程式碼的部分更改</li>\n<li>whole 輸出整個程式碼文件</li>\n</ul>\n<h1 id=\"livebench\"><a class=\"anchor\" href=\"#livebench\">#</a> LiveBench</h1>\n<div class=\"links\"><div class=\"item\" title=\"LiveBench\" style=\"--block-color:#e9546b;\"><a href=\"https://livebench.ai/\" class=\"image\" data-background-image=\"https://livebench.ai/favicon.ico\"></a>\n        <div class=\"info\">\n        <a href=\"https://livebench.ai/\" class=\"title\">LiveBench</a>\n        <p class=\"desc\">https://livebench.ai/</p>\n        </div></div></div>\n<p>LiveBench 是一個用於評估大型語言模型（LLM）的基準測試平台，目標是防止測試集污染並提供客觀評分。</p>\n<ul>\n<li>每月更新問題，確保模型沒有見過這些問題</li>\n<li>可以自行驗證分數，也可以接入模型 API 進行跑分</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/LiveBench.webp\" alt=\"\" title=\"LiveBench\" width=\"80%\" /></p>\n<h1 id=\"livecodebench\"><a class=\"anchor\" href=\"#livecodebench\">#</a> LiveCodeBench</h1>\n<div class=\"links\"><div class=\"item\" title=\"LiveCodeBench\" style=\"--block-color:#e9546b;\"><a href=\"https://livecodebench.github.io/leaderboard.html\" class=\"image\" data-background-image=\"https://livecodebench.github.io/images/favicon.svg\"></a>\n        <div class=\"info\">\n        <a href=\"https://livecodebench.github.io/leaderboard.html\" class=\"title\">LiveCodeBench</a>\n        <p class=\"desc\">https://livecodebench.github.io/leaderboard.html</p>\n        </div></div></div>\n<p>LiveCodeBench 是由加州大學柏克萊分校、MIT、康乃爾大學等團隊共同開發的程式碼大型語言模型（Code LLMs）評估基準</p>\n<ul>\n<li>持續更新的題目庫，<strong>避免資料污染</strong>的模型效能評測</li>\n<li>使用 <strong>LeetCode、AtCoder、Codeforces</strong> 平台的程式競賽題目</li>\n<li>可以調整題目時間，確保在模型的訓練截止日期之後</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI_BenchMark/LiveCodeBench.webp\" alt=\"\" title=\"LiveCodeBench\" width=\"80%\" /></p>\n",
            "tags": [
                "llm",
                "benchmark",
                "LMSYS",
                "Chatbot Arena",
                "livebench",
                "aider"
            ]
        },
        {
            "id": "https://blog.minz.li/AI/AI-Accelerators/",
            "url": "https://blog.minz.li/AI/AI-Accelerators/",
            "title": "超越 GPU 在 Groq/Cerebras/SambaNova 使用高速輸出的 Deepseek",
            "date_published": "2025-02-19T16:00:00.000Z",
            "content_html": "<h1 id=\"groq-介紹\"><a class=\"anchor\" href=\"#groq-介紹\">#</a> Groq 介紹</h1>\n<p>Groq 的主要產品是 LPU (Language Processing Units)，能夠大幅提升模型的推論速度，這表示模型回答的速度加快，比 GPT-4o 快了數倍。<br />\nGroq 的 實驗性模型  <code>llama-3.3-70b-specdec</code>  在 GroqCloud 上的推論速度最快可以達到 <a href=\"https://groq.com/groq-first-generation-14nm-chip-just-got-a-6x-speed-boost-introducing-llama-3-1-70b-speculative-decoding-on-groqcloud/\">1,660 tokens/s</a> 。</p>\n<ul>\n<li>低延遲 (Seconds to First Token Received)</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://groq.com/wp-content/uploads/2024/11/latency-1536x762.jpg.webp\" alt=\"\" /></p>\n<ul>\n<li>高性能 (High Output Tokens per Second)</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://groq.com/wp-content/uploads/2024/11/output-speed2-1536x762.jpg.webp\" alt=\"\" /></p>\n<h2 id=\"可以使用的-models\"><a class=\"anchor\" href=\"#可以使用的-models\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://console.groq.com/docs/models\">https://console.groq.com/docs/models</a> 查看可以使用的模型</li>\n<li>目前多為 llama、gemma、whisper 系列</li>\n</ul>\n<h2 id=\"使用\"><a class=\"anchor\" href=\"#使用\">#</a> 使用</h2>\n<p>可以在官方網站 <a href=\"https://groq.com/\">https://groq.com/</a> 或是<a href=\"https://console.groq.com/playground\"> playground</a> 直接使用</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/groq_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api\"><a class=\"anchor\" href=\"#api\">#</a> API</h2>\n<p><a href=\"https://console.groq.com/keys\">https://console.groq.com/keys</a><br />\n 在左邊 API Keys 的選單中點擊 Create API Key，目前免費層級有提供一定的額度使用，API 兼容 openai 格式，修改 base_url 和 model 後可以直接使用。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> openai</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>client <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>OpenAI<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    base_url<span class=\"token operator\">=</span><span class=\"token string\">\"https://api.groq.com/openai/v1\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    api_key<span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"GROQ_API_KEY\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"cerebras-介紹\"><a class=\"anchor\" href=\"#cerebras-介紹\">#</a> Cerebras 介紹</h1>\n<p>Cerebras 研發的產品是 Wafer Scale Engine（WSE，晶圓級引擎），是一款 超大型 AI 加速晶片。</p>\n<ul>\n<li><a href=\"https://cerebras.ai/blog/cerebras-launches-worlds-fastest-deepseek-r1-llama-70b-inference\">推理速度</a></li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://cerebras.ai/wp-content/uploads/2025/01/deepseek-chart.png\" alt=\"\" /></p>\n<h2 id=\"可以使用的-models-2\"><a class=\"anchor\" href=\"#可以使用的-models-2\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://inference-docs.cerebras.ai/introduction\">https://inference-docs.cerebras.ai/introduction</a> 查看可以使用的模型</li>\n<li>目前只有 llama 系列</li>\n</ul>\n<h2 id=\"使用-2\"><a class=\"anchor\" href=\"#使用-2\">#</a> 使用</h2>\n<p>可以在首頁<a href=\"https://inference.cerebras.ai/\"> https://inference.cerebras.ai/</a> 直接使用</p>\n<p><img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/cerebras_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api-2\"><a class=\"anchor\" href=\"#api-2\">#</a> API</h2>\n<p><a href=\"https://cloud.cerebras.ai/platform/\">https://cloud.cerebras.ai/platform/</a><br />\n 首頁右上方點擊 Get API Key，<strong>需要填寫 Google 表單申請</strong>，目前免費層級有提供一定的額度使用，<br />\nAPI 兼容 openai 格式，修改 base_url 為  <code>https://api.cerebras.ai/v1</code>  和  <code>model</code>  後可以直接使用。</p>\n<h1 id=\"sambanova-介紹\"><a class=\"anchor\" href=\"#sambanova-介紹\">#</a> Sambanova 介紹</h1>\n<p>SambaNova 開發的產品是 SN40L ，Reconfigurable Dataflow Unit (RDU)，專為 AI 推理與訓練設計的整合式加速晶片。</p>\n<ul>\n<li>SambaNova 與其他競品的比較</li>\n<li><a href=\"https://sambanova.ai/blog/sn40l-chip-best-inference-solution\">來源</a></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">指標</th>\n<th style=\"text-align:center\">SambaNova SN40L</th>\n<th style=\"text-align:center\">Cerebras WSE-3</th>\n<th style=\"text-align:center\">Groq LPU</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">晶片數（70B 模型）</td>\n<td style=\"text-align:center\">16 晶片</td>\n<td style=\"text-align:center\">336 晶片（4 晶圓）</td>\n<td style=\"text-align:center\">576 晶片</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">算力密度</td>\n<td style=\"text-align:center\">優於 Groq 40 倍 / Cerebras 10 倍</td>\n<td style=\"text-align:center\">高算力但受限於 SRAM 與多晶圓管線並行成本</td>\n<td style=\"text-align:center\">需大量晶片互連以補足 SRAM 容量限制</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">記憶體架構</td>\n<td style=\"text-align:center\">SRAM + HBM + DDR</td>\n<td style=\"text-align:center\">全 SRAM</td>\n<td style=\"text-align:center\">全 SRAM</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">量化需求</td>\n<td style=\"text-align:center\">無（16-bit 原生）</td>\n<td style=\"text-align:center\">無（官方宣稱使用 16-bit）</td>\n<td style=\"text-align:center\"><strong>推測</strong>需 int8 量化</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"可以使用的-models-3\"><a class=\"anchor\" href=\"#可以使用的-models-3\">#</a> 可以使用的 Models</h2>\n<ul>\n<li>可以在 <a href=\"https://docs.sambanova.ai/cloud/docs/get-started/supported-models\">https://docs.sambanova.ai/cloud/docs/get-started/supported-models</a> 查看可以使用的模型</li>\n<li>目前只有 DeepSeek、llama、Qwen 系列</li>\n<li>DeepSeek R1 671B 需要填表申請</li>\n</ul>\n<h2 id=\"使用-3\"><a class=\"anchor\" href=\"#使用-3\">#</a> 使用</h2>\n<p>可以在官方網站 <a href=\"https://cloud.sambanova.ai/\">playground</a> 直接使用<br />\n<img loading=\"lazy\" data-src=\"/assets/AI/AI-Accelerators/sambanova_home.webp\" alt=\"\" width=\"80%\" /></p>\n<h2 id=\"api-3\"><a class=\"anchor\" href=\"#api-3\">#</a> API</h2>\n<p><a href=\"https://cloud.sambanova.ai/apis\">https://cloud.sambanova.ai/apis</a><br />\n 在左邊 API Keys 的選單中點擊 Create API Key，目前提供新用戶 5 美元 (3 個月到期)，<br />\nAPI 兼容 openai 格式，修改 base_url 為  <code>https://api.sambanova.ai</code>  和 model 後可以直接使用。</p>\n",
            "tags": [
                "Groq",
                "Cerebras",
                "SambaNova",
                "Deepseek",
                "llama"
            ]
        }
    ]
}